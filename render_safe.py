# æŠŠä¸‹é¢è¿™ä¸¤ä¸ªè·¯å¾„æ”¹æˆä½ æœºå™¨ä¸Šçš„çœŸå®ç»å¯¹è·¯å¾„
DATA_DIR  = Path("/Users/yangjiyue/Desktop/NeRF/my_scene/processed")
CKPT_PATH = Path("/Users/yangjiyue/Desktop/NeRF/outputs/processed/nerfacto/2025-10-29_154943/nerfstudio_models/step-000002999.ckpt")
import os
import torch
from pathlib import Path
import imageio.v2 as imageio
import torch.serialization
import numpy as np

# é˜²æ­¢ Mac ä¸Š OpenMP å¤šå‰¯æœ¬å´©æºƒ
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# ====== Patch torch.load: å…è®¸å®Œæ•´è¿˜åŸ ckpt (PyTorch 2.6 å®‰å…¨é™åˆ¶) ======
_orig_load = torch.load

def trusted_load(f, map_location=None, **kwargs):
    # æˆ‘ä»¬ä¿¡ä»»è‡ªå·±è®­ç»ƒå‡ºæ¥çš„ checkpointï¼Œæ‰€ä»¥å…è®¸åŠ è½½å®Œæ•´å¯¹è±¡
    kwargs["weights_only"] = False

    # PyTorch 2.6 é™åˆ¶ååºåˆ—åŒ–æŸäº› numpy çš„ç±»ï¼Œè¿™é‡Œæ‰‹åŠ¨æ”¾è¡Œ
    with torch.serialization.safe_globals({
        np.core.multiarray.scalar: np.core.multiarray.scalar
    }):
        return _orig_load(f, map_location=map_location, **kwargs)

torch.load = trusted_load
# =====================================================================


def main():
    # --------- è·¯å¾„é…ç½®ï¼ˆæŒ‰ä½ æœºå™¨çš„å®é™…è®­ç»ƒè¾“å‡ºï¼‰---------
    DATA_DIR  = Path("/Users/yangjiyue/Desktop/NeRF/my_scene/processed")
    CKPT_PATH = Path("/Users/yangjiyue/Desktop/NeRF/outputs/processed/nerfacto/2025-10-29_154943/nerfstudio_models/step-000002999.ckpt")

    OUTPUT_DIR = Path("renders/stills_manual")
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    print(">>> ä½¿ç”¨æ•°æ®ç›®å½•:", DATA_DIR)
    print(">>> ä½¿ç”¨ checkpoint:", CKPT_PATH)

    # --------- è¯» checkpoint: ä¼šå¾—åˆ°ä¸€ä¸ª dict ---------
    ckpt = torch.load(CKPT_PATH, map_location="cpu")
    # ckpt.keys() åº”è¯¥åŒ…å«: ['step','pipeline','optimizers','schedulers','scalers']
    pipeline_state = ckpt["pipeline"]

    print(">>> ckpt keys:", ckpt.keys())
    print(">>> pipeline_state ä¾‹å­:", list(pipeline_state.keys())[:10])

    # --------- å¯¼å…¥ nerfstudio çš„å¿…è¦ç»„ä»¶ ---------
    # pipeline / datamanager / model config è¿™äº›ç±»
    from nerfstudio.pipelines.base_pipeline import VanillaPipeline, VanillaPipelineConfig
    from nerfstudio.data.datamanagers.parallel_datamanager import (
        ParallelDataManager,
        ParallelDataManagerConfig,
    )
    from nerfstudio.data.pixel_samplers import PixelSampler, PixelSamplerConfig
    from nerfstudio.data.dataparsers.nerfstudio_dataparser import (
        Nerfstudio as NerfstudioDataParser,
        NerfstudioDataParserConfig,
    )
    from nerfstudio.models.nerfacto import NerfactoModel, NerfactoModelConfig

    # æ¸²æŸ“è¦ç”¨åˆ°çš„ç›¸æœºå’Œå°„çº¿å·¥å…·
    from nerfstudio.cameras.cameras import Cameras
    from nerfstudio.cameras.rays import RayBundle

    print(">>> æ­å»ºæ¨ç†é…ç½®(ParallelDataManager / å•è¿›ç¨‹æ¨¡å¼)...")

    # dataparser: è´Ÿè´£ä» processed æ•°æ®ä¸­è¯»å–ç›¸æœºä½å§¿ / intrinsics / imgs
    dataparser_cfg = NerfstudioDataParserConfig(
        _target=NerfstudioDataParser,
        data=Path("."),      # ä¼šç›¸å¯¹äº DATA_DIR è§£æ
        scale_factor=1.0,
        scene_scale=1.0,
        orientation_method="up",
        center_method="poses",
        auto_scale_poses=True,

        eval_mode="fraction",
        train_split_fraction=0.9,
        eval_interval=8,
    )

    # datamanager: æŠŠæ•°æ®å–‚ç»™æ¨¡å‹
    # æˆ‘ä»¬ç”¨ ParallelDataManager ä½†æŠŠ num_processes=0ï¼Œè¿™æ ·å®ƒä¸ä¼šå¼€å­è¿›ç¨‹ï¼ˆMac ä¸Šå®‰å…¨ï¼‰
    datamanager_cfg = ParallelDataManagerConfig(
        _target=ParallelDataManager,
        data=DATA_DIR,
        dataparser=dataparser_cfg,

        # batch å¤§å°å°ä¸€ç‚¹ï¼Œå› ä¸ºæˆ‘ä»¬è·‘ CPU
        train_num_rays_per_batch=1024,
        eval_num_rays_per_batch=1024,

        pixel_sampler=PixelSamplerConfig(
            _target=PixelSampler,
            num_rays_per_batch=1024,
            keep_full_image=False,
            is_equirectangular=False,
            rejection_sample_mask=True,
        ),

        camera_res_scale_factor=1.0,

        # ğŸ’¡ å…³é”®ï¼šä¸èµ°å¤šè¿›ç¨‹
        num_processes=0,
        queue_size=1,
    )

    # Nerfacto æ¨¡å‹é…ç½®ï¼ˆCPU ç‰ˆæœ¬ï¼Œimplementation="torch"ï¼‰
    model_cfg = NerfactoModelConfig(
        _target=NerfactoModel,
        implementation="torch",   # ä¸ç”¨ tiny-cuda-nnï¼Œçº¯ PyTorch
        eval_num_rays_per_chunk=4096,
        hidden_dim=64,
        hidden_dim_color=64,
        near_plane=0.05,
        far_plane=1000.0,
        background_color="last_sample",
    )

    # pipeline = datamanager + model
    pipeline_cfg = VanillaPipelineConfig(
        _target=VanillaPipeline,
        datamanager=datamanager_cfg,
        model=model_cfg,
    )

    print(">>> æ ¹æ® config å®ä¾‹åŒ– pipeline (CPU)...")
    pipeline: VanillaPipeline = pipeline_cfg.setup(device=torch.device("cpu"))

    model = pipeline.model
    datamanager = pipeline.datamanager
    model.eval()  # å…³æ‰è®­ç»ƒæ¨¡å¼ï¼Œæ¨ç†ç”¨

    # --------- æŠŠ ckpt çš„æƒé‡å¡å› model ---------
    # ckpt["pipeline"] é‡Œæ˜¯å„ç§ module çš„ state_dictï¼Œä½† key å¸¦å‰ç¼€ï¼Œæ¯”å¦‚ "_model.xxx"
    model_state = {}
    for k, v in pipeline_state.items():
        if k.startswith("_model."):
            new_k = k[len("_model."):]
            model_state[new_k] = v
        elif k.startswith("model."):
            new_k = k[len("model."):]
            model_state[new_k] = v
        # å…¶ä»– key (æ¯”å¦‚ datamanager é‡Œçš„çŠ¶æ€) æˆ‘ä»¬å¿½ç•¥

    print(">>> ä» ckpt æå–åˆ°çš„æ¨¡å‹å‚æ•°ä¸ªæ•°:", len(model_state))
    missing, unexpected = model.load_state_dict(model_state, strict=False)
    print(">>> missing keys:", missing)
    print(">>> unexpected keys:", unexpected)

    # --------- æ‰¾åˆ°æˆ‘ä»¬è¦æ¸²æŸ“çš„ç›¸æœºè§†è§’ ---------
    # datamanager é€šå¸¸ä¼šæœ‰ eval_dataset
    eval_dataset = getattr(datamanager, "eval_dataset", None)
    if eval_dataset is None and hasattr(datamanager, "get_eval_dataset"):
        eval_dataset = datamanager.get_eval_dataset()
    if eval_dataset is None:
        print(">>> æ²¡æœ‰ eval_datasetï¼Œå°è¯• train_dataset")
        eval_dataset = getattr(datamanager, "train_dataset", None)
    if eval_dataset is None:
        raise RuntimeError("æ— æ³•æ‹¿åˆ°å¯æ¸²æŸ“çš„æ•°æ®é›† (eval/train éƒ½ä¸ºç©º)")

    num_views_to_render = min(5, len(eval_dataset))
    print(f">>> å¼€å§‹æ¸²æŸ“å‰ {num_views_to_render} ä¸ªè§†è§’åˆ° PNG ...")

    # --------- å¾ªç¯æ¯ä¸ªè§†è§’ï¼Œç”ŸæˆRGBå¹¶ä¿å­˜ ---------
    for i in range(num_views_to_render):
        sample = eval_dataset[i]

        # ä¸åŒ nerfstudio ç‰ˆæœ¬è¿”å›çš„ç»“æ„ä¸å®Œå…¨ä¸€æ ·
        # 1) æœ‰çš„è¿”å› dict{'cameras': Cameras, 'image': ...}
        # 2) æœ‰çš„ç›´æ¥æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œå±æ€§é‡Œæœ‰ .cameras
        if isinstance(sample, dict) and "cameras" in sample:
            cam: Cameras = sample["cameras"]
        elif hasattr(sample, "cameras"):
            cam: Cameras = sample.cameras
        else:
            raise RuntimeError(
                "è¿™ä¸ª nerfstudio ç‰ˆæœ¬çš„ eval_dataset[i] æ‹¿ä¸åˆ° camerasã€‚"
            )

        # ç”¨ç›¸æœºç”Ÿæˆå°„çº¿ RayBundle (æ¯ä¸ªåƒç´ å¯¹åº”ä¸€æ¡å…‰çº¿ï¼ŒåŒ…å«æ–¹å‘/åŸç‚¹ç­‰)
        ray_bundle: RayBundle = cam.generate_rays(device=torch.device("cpu"))

        with torch.no_grad():
            # NerfactoModel æœ‰æ–¹æ³• get_outputs_for_camera_ray_bundle
            outputs = model.get_outputs_for_camera_ray_bundle(ray_bundle)
            # é‡Œé¢é€šå¸¸æœ‰ 'rgb' è¿™ä¸ª key: å½¢çŠ¶ [H, W, 3]ï¼ŒèŒƒå›´åœ¨ [0,1]
            rgb = outputs["rgb"]

        rgb_np = rgb.cpu().numpy()
        rgb_np = (rgb_np * 255).astype(np.uint8)

        out_path = OUTPUT_DIR / f"manual_frame_{i:03d}.png"
        imageio.imwrite(out_path, rgb_np)
        print(f"âœ… å·²ä¿å­˜ {out_path}")

    print(">>> å…¨éƒ¨å®Œæˆï¼å»çœ‹çœ‹ renders/stills_manual/ é‡Œçš„ PNG å§ã€‚")


if __name__ == "__main__":
    main()
